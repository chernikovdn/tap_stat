{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики:\n",
    "# RPU - rub per uet - стоимость 1 УЕТы\n",
    "# FPV - filling per visit - отношение числа пломб к числу приемов\n",
    "# DPV - devitalization per vizit - отношение числа мышьяков к числу приемов\n",
    "# Плановое среднее значение стоимости 1 УЕТы в 2021 году = 166,26 руб.\n",
    "# Плановое среднее значение стоимости 1 УЕТы в 2022 году = 167,70 руб."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRVS:\n",
    "# 72 - хирурги\n",
    "# 87 - физио"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from simpledbf import Dbf5\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from plotly.colors import n_colors\n",
    "\n",
    "from datetime import date, datetime\n",
    "from pandas.tseries.offsets import MonthEnd, MonthBegin\n",
    "\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl import worksheet\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим максимальный период, уже находящийся в директории для загрузки\n",
    "\n",
    "def get_max_loaded_period(cur_path):\n",
    "    \n",
    "    max_period = 0\n",
    "    max_loaded_period = ''\n",
    "    \n",
    "    for dr in os.listdir(cur_path):\n",
    "        if int(dr[-5:-1]) > max_period:\n",
    "            max_period = int(dr[-5:-1])\n",
    "            max_loaded_period = dr\n",
    "            \n",
    "    return max_loaded_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рекурсивный обход директории и поиск u-файлов, возврат списка u-файлов\n",
    "\n",
    "def read_u_files(cur_path, dbf_files):\n",
    "    \n",
    "    for dr in os.listdir(cur_path):\n",
    "        \n",
    "        abs_path = os.path.join(cur_path, dr)\n",
    "\n",
    "        if os.path.isdir(abs_path):\n",
    "            read_u_files(abs_path, dbf_files)\n",
    "        elif 'u' in dr[0].lower() and dr[-4:].lower() == '.dbf':\n",
    "            dbf_files.append(abs_path)\n",
    "\n",
    "    return dbf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рекурсивный обход директории и поиск d-файлов, возврат списка d-файлов\n",
    "\n",
    "def read_d_files(cur_path, dbf_files):\n",
    "    \n",
    "    for dr in os.listdir(cur_path):\n",
    "        \n",
    "        abs_path = os.path.join(cur_path, dr)\n",
    "        \n",
    "        if os.path.isdir(abs_path):\n",
    "            read_d_files(abs_path, dbf_files)\n",
    "        elif 'd' in dr[0].lower() and dr[-4:].lower() == '.dbf':\n",
    "            dbf_files.append(abs_path)\n",
    "\n",
    "    return dbf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рекурсивный обход директории и поиск z-файлов, возврат списка z-файлов\n",
    "\n",
    "def read_z_files(cur_path, dbf_files):\n",
    "    \n",
    "    for dr in os.listdir(cur_path):\n",
    "        \n",
    "        abs_path = os.path.join(cur_path, dr)\n",
    "        \n",
    "        if os.path.isdir(abs_path):\n",
    "            read_z_files(abs_path, dbf_files)\n",
    "        elif 'z' in dr[0].lower() and dr[-4:].lower() == '.dbf':\n",
    "            dbf_files.append(abs_path)\n",
    "\n",
    "    return dbf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим u-файлы, выберем только нужные колонки\n",
    "def read_u_dbf(year=0):\n",
    "#     Передаем путь, по которому найдем все dbf файлы для загрузки  \n",
    "    if year == 0:  \n",
    "        u_files_to_load = read_u_files(dbf_path_all, [])\n",
    "    else:\n",
    "        u_files_to_load = read_u_files(dbf_path_year, [])\n",
    "    df_u = pd.DataFrame()\n",
    "    for f in u_files_to_load:\n",
    "        # Сразу забираем только нужные колонки\n",
    "        df_tmp = Dbf5(f, codec='cp866').to_dataframe()\n",
    "        df_tmp = df_tmp[['OT_PER', 'MSK_OT', 'PERSCODE', 'NHISTORY', 'PROFIL', 'MKB1', 'MKB2', 'MKB3', 'CODE_USL',\n",
    "                         'CODE_MD', 'DATE_IN', 'KOL_USL', 'RES_GOSP', 'ISH_MOV', 'TARIF_B', 'SUM_RUB', 'CODE_OTD',\n",
    "                         'P_CEL', 'MKB0', 'C_ZAB', 'OT_PER_U', 'IDCASE']]\n",
    "        df_u = pd.concat([df_u, df_tmp], ignore_index=True)\n",
    "        # Этот вариант на 50% дольше\n",
    "        # df_u = pd.concat([df_u, Dbf5(f, codec='cp866').to_dataframe()], ignore_index=True)\n",
    "        # break\n",
    "    return df_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - загрузим все года\n",
    "def read_d_dbf(year=0):\n",
    "#     Передаем путь, по которому найдем все dbf файлы для загрузки\n",
    "    if year == 0:\n",
    "        d_files_to_load = read_d_files(dbf_path_all, [])\n",
    "    else:\n",
    "        d_files_to_load = read_d_files(dbf_path_year, [])\n",
    "    df_d = pd.DataFrame()\n",
    "    for f in d_files_to_load:\n",
    "        df_tmp = Dbf5(f, codec='cp866').to_dataframe()\n",
    "        df_tmp = df_tmp[['OT_PER', 'CODE_MD', 'FIO_MD', 'KATEG_MD', 'SPEC_MD', 'MD_SS', 'PRVS']]\n",
    "        df_tmp['MSK_OT'] = f[-10:-8]  # Добавим код страховой для верного объединения с u-файлом\n",
    "        df_d = pd.concat([df_d, df_tmp], ignore_index=True)\n",
    "    return df_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим z-файлы, выберем только нужные колонки\n",
    "def read_z_dbf(year=0):\n",
    "#     Передаем путь, по которому найдем все dbf файлы для загрузки  \n",
    "    if year == 0:  \n",
    "        z_files_to_load = read_z_files(dbf_path_all, [])\n",
    "    else:\n",
    "        z_files_to_load = read_z_files(dbf_path_year, [])\n",
    "    df_z = pd.DataFrame()\n",
    "    for f in z_files_to_load:\n",
    "        # Сразу забираем только нужные колонки\n",
    "        df_tmp = Dbf5(f, codec='cp866').to_dataframe()\n",
    "        df_tmp = df_tmp[['OT_PER', 'PERSCODE', 'NHISTORY', 'CODE_USL','DATE_OUT', 'TEETH_CODE']]\n",
    "        df_z = pd.concat([df_z, df_tmp], ignore_index=True)\n",
    "        \n",
    "    df_z = df_z.rename(columns={'DATE_OUT': 'DATE_IN'})\n",
    "    return df_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year - загрузим только нужный год\n",
    "# year = 0 - загрузим все года\n",
    "year = 2022\n",
    "\n",
    "# структура папок должна соответствовать (.../dbf/year/.../*.dbf, например .../dbf/2022/.../*.dbf)\n",
    "dbf_path_all = '../no_mkb2_u0621/dbf'\n",
    "dbf_path_year = f'../no_mkb2_u0621/dbf/{year}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перезапишем максимальный период (этот период периодически пересобирается)\n",
    "# Предыдущие периоды не трогаем, если вдруг нужно их перезаписать, то копируем руками выборочно нужный период\n",
    "# Новый период появляется уже в новом месяце, когда предыдущий период уже собран полностью и не требует перезаписи\n",
    "\n",
    "# Создадим временную заглушку для year == 0, нужно будет продумать загрузку всех периодов и нужно ли?\n",
    "if year == 0:\n",
    "    year = 2022\n",
    "\n",
    "reestr_path = 'D:/Электронная регистратура/BIN_MIS/bin_mo/Reestr/TFOMS_1/'\n",
    "\n",
    "max_loaded_period = get_max_loaded_period(dbf_path_year)\n",
    "\n",
    "shutil.copytree(src=os.path.join(reestr_path, max_loaded_period), \n",
    "                dst=f'{dbf_path_year}/{max_loaded_period}', \n",
    "                dirs_exist_ok=True,\n",
    "                ignore = shutil.ignore_patterns('*.zip', '*.xls', '*.enc', '*.pdf'))\n",
    "\n",
    "# Смотрим, появился ли в каталоге реестров новый период, больше чем уже загруженный\n",
    "# Директории имеют название \"REESTR_3613015005221\", где:\n",
    "# REESTR_+{код=361301}+{регион=50}+{период_ММГГ=0522}+{номер_пакета=1}\n",
    "# Тогда добавляя 1000 к численной части названия директории мы по сути будем итерироваться по месяцам\n",
    "next_period = f'REESTR_{int(max_loaded_period[-13:]) + 1000}'\n",
    "next_period_path = os.path.join(reestr_path, next_period)\n",
    "\n",
    "# Мало ли мы не запускали скрипт несколько месяцев, тогда в цикле подгрузим все директории,\n",
    "# более поздние относительно уже загруженной\n",
    "while os.path.isdir(os.path.join(reestr_path, next_period)):\n",
    "    shutil.copytree(src=next_period_path, \n",
    "                    dst=f'{dbf_path_year}/{next_period}', \n",
    "                    dirs_exist_ok=True,\n",
    "                    ignore = shutil.ignore_patterns('*.zip', '*.xls', '*.enc', '*.pdf'))\n",
    "    next_period = f'REESTR_{int(next_period[-13:]) + 1000}'\n",
    "    next_period_path = os.path.join(reestr_path, next_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получим актуальный максимальный период в исходных загружаемых данных\n",
    "current_max_period = get_max_loaded_period(dbf_path_year)[-5:-1]\n",
    "current_max_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_u = read_u_dbf(year)\n",
    "df_all_d = read_d_dbf(year)\n",
    "df_all_z = read_z_dbf(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Плановая средняя стоимость 1 УЕТ\n",
    "# Стоимости УЕТ разнятся в зависимости от типа услуги\n",
    "\n",
    "mean_uet = 0\n",
    "if year == 2021:\n",
    "    mean_uet = 166.26\n",
    "elif year == 2022:\n",
    "    mean_uet = 167.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # В OT_PER_U == OT_PER попадают перевыставленные случаи, а значит присутсвуют в прошлых периодах\n",
    "# df_all_u = df_all_u[df_all_u['OT_PER'] == df_all_u['OT_PER_U']]\n",
    "\n",
    "# df_all_u['DATE_IN'] = pd.to_datetime(df_all_u['DATE_IN'])\n",
    "\n",
    "# # Загрузим тарифы в УЕТ (берем октябрь 2021, так как в течение 2021 года тарифы в УЕТ не изменялись\n",
    "# # для верности будем брать mdu посвежее, хотя изменений по стоматологии там и не было\n",
    "# # и объеденим с u-датафреймом\n",
    "# # df_mdu = pd.read_excel('../no_mkb2_u0621/dbf/mdu1021_dbf.xlsx')\n",
    "# df_mdu = pd.read_excel('../no_mkb2_u0621/dbf/mdu0122_dbf.xlsx')\n",
    "# df_mdu = df_mdu[df_mdu['KOL_UET'] > 0]\n",
    "# df_all_u_uet = pd.merge(df_all_u, df_mdu[['CODE_USL', 'NAME_USL', 'KOL_UET']], how='left', on='CODE_USL')\n",
    "# df_all = pd.merge(df_all_u_uet, df_all_d[['OT_PER', 'MSK_OT', 'CODE_MD', 'FIO_MD', 'SPEC_MD', 'MD_SS', 'PRVS']],\n",
    "#                   how='left', on=['OT_PER', 'MSK_OT', 'CODE_MD'])\n",
    "# df_all['SUM_UET'] = df_all['KOL_UET']*df_all['KOL_USL']\n",
    "\n",
    "# df_all['SUM_RUB'] = np.around(df_all['SUM_RUB'], decimals=2)\n",
    "# # Отметим физио отдельно\n",
    "# df_all.loc[df_all['PRVS'] == 87, 'FIO_MD'] += ' физио'\n",
    "\n",
    "# # В 2021 была корректировка ФИО\n",
    "# df_all['FIO_MD'] = df_all['FIO_MD'].str.replace(pat='Горбикова Элла Рашитовна',\n",
    "#                                                 repl='Горбикова Эльфия Рашитовна')\n",
    "# df_all['FIO_MD'] = df_all['FIO_MD'].str.replace(pat='Камынова Наталия Валерьевна',\n",
    "#                                                 repl='Камынова Наталия Валериевна')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В OT_PER_U == OT_PER попадают перевыставленные случаи, а значит присутсвуют в прошлых периодах\n",
    "df_all_u = df_all_u[df_all_u['OT_PER'] == df_all_u['OT_PER_U']]\n",
    "\n",
    "df_all_u['DATE_IN'] = pd.to_datetime(df_all_u['DATE_IN'])\n",
    "df_all_z['DATE_IN'] = pd.to_datetime(df_all_z['DATE_IN'])\n",
    "\n",
    "# Загрузим тарифы в УЕТ (берем октябрь 2021, так как в течение 2021 года тарифы в УЕТ не изменялись\n",
    "# для верности будем брать mdu посвежее, хотя изменений по стоматологии там и не было\n",
    "# и объеденим с u-датафреймом\n",
    "# df_mdu = pd.read_excel('../no_mkb2_u0621/dbf/mdu1021_dbf.xlsx')\n",
    "df_mdu = pd.read_excel('../no_mkb2_u0621/dbf/mdu0122_dbf.xlsx')\n",
    "df_mdu = df_mdu[df_mdu['KOL_UET'] > 0]\n",
    "df_all = df_all_u \\\n",
    "            .merge(df_mdu[['CODE_USL', 'NAME_USL', 'KOL_UET']], how='left', on='CODE_USL') \\\n",
    "            .merge(df_all_d[['OT_PER', 'MSK_OT', 'CODE_MD', 'FIO_MD', 'SPEC_MD', 'MD_SS', 'PRVS']],\n",
    "                   how='left', on=['OT_PER', 'MSK_OT', 'CODE_MD']) \\\n",
    "#             .merge(df_all_z, how='left', on=['OT_PER', 'PERSCODE', 'NHISTORY', 'CODE_USL', 'DATE_IN'])\n",
    "\n",
    "df_all['SUM_UET'] = df_all['KOL_UET']*df_all['KOL_USL']\n",
    "\n",
    "df_all['SUM_RUB'] = np.around(df_all['SUM_RUB'], decimals=2)\n",
    "# Отметим физио отдельно\n",
    "df_all.loc[df_all['PRVS'] == 87, 'FIO_MD'] += ' физио'\n",
    "\n",
    "# В 2021 была корректировка ФИО\n",
    "df_all['FIO_MD'] = df_all['FIO_MD'].str.replace(pat='Горбикова Элла Рашитовна',\n",
    "                                                repl='Горбикова Эльфия Рашитовна')\n",
    "df_all['FIO_MD'] = df_all['FIO_MD'].str.replace(pat='Камынова Наталия Валерьевна',\n",
    "                                                repl='Камынова Наталия Валериевна')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обозначение типа специальности\n",
    "\n",
    "df_all['spec'] = df_all \\\n",
    "                    .PRVS \\\n",
    "                    .map({208: 'тер', 72: 'хир', 69: 'тер', 71: 'тер', 87: 'физио'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Этот вариант компактный, но что если будет врач без ФИО, плюс физио (добавка после отчества) не выделяется\n",
    "\n",
    "# fio_map = {x: x.split()[0][0:5] + x.split()[1][0:1] + x.split()[2][0:1] for x in df_all.FIO_MD.unique()}\n",
    "# fio_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим сокращенное ФИО для выгрузки в дашборд\n",
    "\n",
    "fio_map = {}\n",
    "for fio in df_all.FIO_MD.unique():\n",
    "    short_fio = ''\n",
    "    f = True  # У первого элемента (фамилии) нужно оставить 5 символов, у остальных по 1\n",
    "    for part_fio in fio.split():\n",
    "        if f:\n",
    "            short_fio += part_fio[0:3]\n",
    "            f = False  # Все остальные уже не первые\n",
    "        else:\n",
    "            short_fio += part_fio[0:1]\n",
    "    fio_map.update({fio: short_fio})\n",
    "fio_map\n",
    "\n",
    "df_all['fio_short'] = df_all \\\n",
    "                        .FIO_MD \\\n",
    "                        .map(fio_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись Excel выгрузок со статистиками по средним значениям УЕТ и ТАП\n",
    "\n",
    "# 1. total_usl - анализ услуг по их стоимости и отклолнению от среднего значения 1 УЕТ\n",
    "df_to_excel = df_all.groupby(['CODE_USL', 'NAME_USL'], as_index=False) \\\n",
    "    .agg({'KOL_USL': 'sum', 'SUM_RUB': 'sum', 'SUM_UET': 'sum', 'KOL_UET': 'max', 'TARIF_B': 'max'})\n",
    "\n",
    "# DEVIATION - отклонение в рублях по услуге от средней плановой стоимости 1 УЕТы\n",
    "df_to_excel['DEVIATION'] = df_to_excel['SUM_RUB']-df_to_excel['KOL_USL']*mean_uet*df_to_excel['KOL_UET']\n",
    "\n",
    "# Доля услуги в общем доходе и выработке\n",
    "total_rub = df_to_excel['SUM_RUB'].sum()\n",
    "total_uet = df_to_excel['SUM_UET'].sum()\n",
    "df_to_excel['part_rub'] = np.around(df_to_excel['SUM_RUB']*100/total_rub, decimals=2)\n",
    "df_to_excel['part_uet'] = np.around(df_to_excel['SUM_UET']*100/total_uet, decimals=2)\n",
    "df_to_excel['part_diff'] = df_to_excel['part_rub'] - df_to_excel['part_uet']\n",
    "df_to_excel.to_excel('total_usl.xlsx')\n",
    "\n",
    "# 2. total_usl_by_doc - аналогично п.1, но в разбивке по врачу (позволит найти существенные проблемы)\n",
    "df_to_excel = df_all.groupby(['FIO_MD', 'CODE_USL', 'NAME_USL'], as_index=False).\\\n",
    "    agg({'KOL_USL': 'sum', 'SUM_RUB': 'sum', 'SUM_UET': 'sum', 'KOL_UET': 'max', 'TARIF_B': 'max'})\n",
    "df_to_excel['DEVIATION'] = df_to_excel['SUM_RUB']-df_to_excel['KOL_USL']*mean_uet*df_to_excel['KOL_UET']\n",
    "df_to_excel['part_rub'] = np.around(df_to_excel['SUM_RUB']*100/total_rub, decimals=2)\n",
    "df_to_excel['part_uet'] = np.around(df_to_excel['SUM_UET']*100/total_uet, decimals=2)\n",
    "df_to_excel['part_diff'] = df_to_excel['part_rub'] - df_to_excel['part_uet']\n",
    "df_to_excel.to_excel('total_usl_by_doc.xlsx')\n",
    "\n",
    "# 3. total_usl_by_doc_period - аналогично п.2, но еще и в разбивке по месяцам\n",
    "df_mean_tap = df_all.groupby(['OT_PER', 'FIO_MD', 'NHISTORY'], as_index=False) \\\n",
    "    .agg({'SUM_UET': 'sum'}) \\\n",
    "    .groupby(['OT_PER', 'FIO_MD'], as_index=False) \\\n",
    "    .agg({'SUM_UET': 'mean'}) \\\n",
    "    .rename(columns={'SUM_UET': 'MEAN_TAP'})\n",
    "df_to_excel = df_all.groupby(['OT_PER', 'FIO_MD'], as_index=False) \\\n",
    "    .agg({'SUM_RUB': 'sum', 'SUM_UET': 'sum'})\n",
    "df_to_excel = pd.merge(df_to_excel, df_mean_tap, how='left', on=['OT_PER', 'FIO_MD'])\n",
    "df_to_excel['DEVIATION'] = df_to_excel['SUM_RUB']-df_to_excel['SUM_UET']*mean_uet\n",
    "df_to_excel = df_to_excel.pivot(index='FIO_MD', columns='OT_PER', values=['DEVIATION', 'MEAN_TAP'])\n",
    "\n",
    "# По каждой колонке добавим строку с итогами\n",
    "columns = [column for column in df_to_excel.columns]\n",
    "data = []\n",
    "for column in columns:\n",
    "    data.append(df_to_excel[column].sum())\n",
    "itog = pd.DataFrame(data=[data], columns=columns, index=['ИТОГО:'])\n",
    "df_to_excel = pd.concat([df_to_excel, itog])\n",
    "df_to_excel.to_excel(\"total_usl_by_doc_period.xlsx\", float_format='%.1f', index_label='ФИО врача')\n",
    "wb = load_workbook(\"total_usl_by_doc_period.xlsx\")\n",
    "ws = wb.active\n",
    "\n",
    "# Установим ширину столбца с ФИО\n",
    "ws.column_dimensions['A'] = worksheet.dimensions.ColumnDimension(ws, index='A', width=38)\n",
    "wb.save(\"total_usl_by_doc_period.xlsx\")\n",
    "\n",
    "# 4. total_usl_cheapest_by_doc - 10 самых \"дешевых\" услуг по каждлому врачу\n",
    "\n",
    "df_to_excel = df_all.groupby(['FIO_MD', 'CODE_USL', 'NAME_USL'], as_index=False).\\\n",
    "    agg({'KOL_USL': 'sum', 'SUM_RUB': 'sum', 'SUM_UET': 'sum', 'KOL_UET': 'max', 'TARIF_B': 'max'})\n",
    "df_to_excel['DEVIATION'] = df_to_excel['SUM_RUB']-df_to_excel['KOL_USL']*mean_uet*df_to_excel['KOL_UET']\n",
    "df_to_excel['part_rub'] = np.around(df_to_excel['SUM_RUB']*100/total_rub, decimals=2)\n",
    "df_to_excel['part_uet'] = np.around(df_to_excel['SUM_UET']*100/total_uet, decimals=2)\n",
    "df_to_excel['part_diff'] = df_to_excel['part_rub'] - df_to_excel['part_uet']\n",
    "df_to_xls = df_to_excel.sort_values(['FIO_MD', 'DEVIATION']).groupby('FIO_MD', as_index=False).head(10)\n",
    "df_to_xls \\\n",
    "    .rename(columns={'FIO_MD': 'ФИО', 'CODE_USL': 'Код', 'NAME_USL': 'Услуга', 'KOL_USL': 'Кол-во',\n",
    "                     'SUM_RUB': 'Всего Руб', 'SUM_UET': 'Всего УЕТ', 'KOL_UET': 'Тариф УЕТ', 'TARIF_B': 'Тариф Руб',\n",
    "                     'DEVIATION': 'Отклонение', 'part_rub': 'Доля в руб', 'part_uet': 'Доля в УЕТ',\n",
    "                     'part_diff': 'Доля отклонения'}) \\\n",
    "    .to_excel('total_usl_cheapest_by_doc.xlsx')\n",
    "\n",
    "# 5. total_usl_expensive_by_doc - 10 самых \"дешевых\" услуг по каждлому врачу\n",
    "\n",
    "df_to_excel = df_all.groupby(['FIO_MD', 'CODE_USL', 'NAME_USL'], as_index=False) \\\n",
    "    .agg({'KOL_USL': 'sum', 'SUM_RUB': 'sum', 'SUM_UET': 'sum', 'KOL_UET': 'max', 'TARIF_B': 'max'})\n",
    "df_to_excel['DEVIATION'] = df_to_excel['SUM_RUB']-df_to_excel['KOL_USL']*mean_uet*df_to_excel['KOL_UET']\n",
    "df_to_excel['part_rub'] = np.around(df_to_excel['SUM_RUB']*100/total_rub, decimals=2)\n",
    "df_to_excel['part_uet'] = np.around(df_to_excel['SUM_UET']*100/total_uet, decimals=2)\n",
    "df_to_excel['part_diff'] = df_to_excel['part_rub'] - df_to_excel['part_uet']\n",
    "df_to_xls = df_to_excel \\\n",
    "    .sort_values(['FIO_MD', 'DEVIATION'], ascending=['True', 'False']) \\\n",
    "    .groupby('FIO_MD', as_index=False) \\\n",
    "    .tail(10)\n",
    "df_to_xls \\\n",
    "    .rename(columns={'FIO_MD': 'ФИО', 'CODE_USL': 'Код', 'NAME_USL': 'Услуга', 'KOL_USL': 'Кол-во',\n",
    "                     'SUM_RUB': 'Всего Руб', 'SUM_UET': 'Всего УЕТ', 'KOL_UET': 'Тариф УЕТ', 'TARIF_B': 'Тариф Руб',\n",
    "                     'DEVIATION': 'Отклонение', 'part_rub': 'Доля в руб', 'part_uet': 'Доля в УЕТ',\n",
    "                     'part_diff': 'Доля отклонения'}) \\\n",
    "    .to_excel('total_usl_expensive_by_doc.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Услуги приема\n",
    "\n",
    "priem = ['B01.065.007V', 'B01.065.008V', 'B01.065.001V', 'B01.065.002V', 'B01.065.003V', 'B01.065.004V', \\\n",
    "         'B01.067.001V', 'B01.067.002V', 'B04.065.006V', 'B04.065.002V', 'B04.065.004V', 'B01.065.005V', \\\n",
    "         'B01.065.006V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Услуги первичного приема\n",
    "\n",
    "priem_first = ['B01.065.007V', 'B01.065.001V', 'B01.065.003V', 'B01.067.001V', 'В01.003.001V', 'B01.065.005V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Услуги установки пломбы\n",
    "\n",
    "filling = ['A16.07.002.001V', 'A16.07.002.002V', 'A16.07.002.003V', 'A16.07.002.004V', 'A16.07.002.005V', \\\n",
    "           'A16.07.002.006V', 'A16.07.002.007V', 'A16.07.002.008V', 'A16.07.002.010V', 'A16.07.002.011V', \\\n",
    "           'A16.07.002.012V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Услуга установки мышьяка\n",
    "\n",
    "devit = 'A11.07.027V'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Услуга стоматоскопии\n",
    "\n",
    "stomatoskop = 'A03.07.001V'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приемы по врачу\n",
    "\n",
    "priem_by_doc = df_all \\\n",
    "                .query('CODE_USL in @priem') \\\n",
    "                .groupby('FIO_MD') \\\n",
    "                .agg({'KOL_USL': 'count'}) \\\n",
    "                .rename(columns={'KOL_USL': 'preim'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приемы по врачу и месяцу\n",
    "\n",
    "priem_by_doc_month = df_all \\\n",
    "                        .query('CODE_USL in @priem') \\\n",
    "                        .groupby(['FIO_MD', 'OT_PER_U']) \\\n",
    "                        .agg({'KOL_USL': 'count'}) \\\n",
    "                        .rename(columns={'KOL_USL': 'preim'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Первичные приемы и стоматоскопии по врачу и месяцу\n",
    "\n",
    "stomatoskop_by_doc_month = df_all \\\n",
    "                            .query('CODE_USL in @priem_first') \\\n",
    "                            .groupby(['FIO_MD', 'OT_PER_U']) \\\n",
    "                            .agg({'KOL_USL': 'count'}) \\\n",
    "                            .rename(columns={'KOL_USL': 'Первичных приемов'}) \\\n",
    "                            .merge(df_all\n",
    "                                        .query('CODE_USL in @stomatoskop')\n",
    "                                        .groupby(['FIO_MD', 'OT_PER_U'])\n",
    "                                        .agg({'KOL_USL': 'count'})\n",
    "                                        .rename(columns={'KOL_USL': 'Люмин. стоматоскопий'}), \n",
    "                                   left_index=True, \n",
    "                                   right_index=True, \n",
    "                                   how='left') \\\n",
    "                            .reset_index() \\\n",
    "                            .pivot(index='FIO_MD', columns='OT_PER_U', values=['Первичных приемов', 'Люмин. стоматоскопий']) \\\n",
    "                            .fillna(0) \\\n",
    "                            .astype('int')\n",
    "stomatoskop_by_doc_month \\\n",
    "    .to_excel(f'Стоматоскопии_{year}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пломбы по врачу\n",
    "\n",
    "filling_by_doc = df_all \\\n",
    "                    .query('CODE_USL in @filling') \\\n",
    "                    .groupby('FIO_MD') \\\n",
    "                    .agg({'KOL_USL': 'sum'}) \\\n",
    "                    .rename(columns={'KOL_USL': 'filling'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пломбы по врачу и месяцу\n",
    "\n",
    "filling_by_doc_month = df_all \\\n",
    "                        .query('CODE_USL in @filling') \\\n",
    "                        .groupby(['FIO_MD', 'OT_PER_U']) \\\n",
    "                        .agg({'KOL_USL': 'sum'}) \\\n",
    "                        .rename(columns={'KOL_USL': 'filling'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наложение девит пасты по врачу\n",
    "\n",
    "devit_by_doc = df_all \\\n",
    "                    .query('CODE_USL == @devit') \\\n",
    "                    .groupby('FIO_MD') \\\n",
    "                    .agg({'KOL_USL': 'sum'}) \\\n",
    "                    .rename(columns={'KOL_USL': 'devit'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наложение девит пасты по врачу и месяцу\n",
    "\n",
    "devit_by_doc_month = df_all \\\n",
    "                        .query('CODE_USL == @devit') \\\n",
    "                        .groupby(['FIO_MD', 'OT_PER_U']) \\\n",
    "                        .agg({'KOL_USL': 'sum'}) \\\n",
    "                        .rename(columns={'KOL_USL': 'devit'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Диагнозы (основной диагноз из ТАП) по врачу\n",
    "\n",
    "diag_by_doc = df_all \\\n",
    "                .groupby(['FIO_MD', 'MKB1', 'NHISTORY'], as_index=False) \\\n",
    "                .agg({'NHISTORY': 'count'}) \\\n",
    "                .rename(columns={'NHISTORY': 'diag_count'}) \\\n",
    "                .groupby(['FIO_MD', 'MKB1'], as_index=False) \\\n",
    "                .agg({'diag_count': 'count'}) \\\n",
    "                .sort_values(['FIO_MD', 'diag_count'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Диагнозы (основной диагноз из ТАП) по врачу и месяцу\n",
    "\n",
    "diag_by_doc_month = df_all \\\n",
    "                        .groupby(['FIO_MD', 'MKB1', 'NHISTORY', 'OT_PER_U'], as_index=False) \\\n",
    "                        .agg({'NHISTORY': 'count'}) \\\n",
    "                        .rename(columns={'NHISTORY': 'diag_count'}) \\\n",
    "                        .groupby(['FIO_MD', 'MKB1', 'OT_PER_U'], as_index=False) \\\n",
    "                        .agg({'diag_count': 'count'}) \\\n",
    "                        .sort_values(['FIO_MD', 'diag_count'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Самые частые диагнозы\n",
    "\n",
    "top_mkb = diag_by_doc \\\n",
    "                .groupby('MKB1', as_index=False) \\\n",
    "                .agg({'diag_count': 'sum'}) \\\n",
    "                .sort_values('diag_count', ascending=False) \\\n",
    "                .head(8) \\\n",
    "                .MKB1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выборка по списку самых частых диагнозов в разрезе врачей\n",
    "\n",
    "top_diag_by_doc = diag_by_doc \\\n",
    "                    .query('MKB1 in @top_mkb') \\\n",
    "                    .pivot(index='FIO_MD', columns='MKB1', values='diag_count') \\\n",
    "                    .fillna(0) \\\n",
    "                    .astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выборка по списку самых частых диагнозов в разрезе врачей и месяцев\n",
    "\n",
    "top_diag_by_doc_month = diag_by_doc_month \\\n",
    "                            .query('MKB1 in @top_mkb') \\\n",
    "                            .pivot(index=['FIO_MD', 'OT_PER_U'], columns='MKB1', values='diag_count') \\\n",
    "                            .fillna(0) \\\n",
    "                            .astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость ТАП в УЕТ\n",
    "\n",
    "avg_uet_by_doc = df_all \\\n",
    "                    .groupby(['FIO_MD', 'NHISTORY'], as_index=False) \\\n",
    "                    .agg({'SUM_UET': 'sum'}) \\\n",
    "                    .groupby('FIO_MD') \\\n",
    "                    .agg({'SUM_UET': 'mean'}) \\\n",
    "                    .round(2) \\\n",
    "                    .rename(columns={'SUM_UET': 'avg_uet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость ТАП в УЕТ по месяцам\n",
    "\n",
    "avg_uet_by_doc_month = df_all \\\n",
    "                        .groupby(['FIO_MD', 'NHISTORY', 'OT_PER_U'], as_index=False) \\\n",
    "                        .agg({'SUM_UET': 'sum'}) \\\n",
    "                        .groupby(['FIO_MD', 'OT_PER_U']) \\\n",
    "                        .agg({'SUM_UET': 'mean'}) \\\n",
    "                        .round(2) \\\n",
    "                        .rename(columns={'SUM_UET': 'avg_uet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость ТАП в рублях\n",
    "\n",
    "avg_rub_by_doc = df_all \\\n",
    "                    .groupby(['FIO_MD', 'NHISTORY'], as_index=False) \\\n",
    "                    .agg({'SUM_RUB': 'sum'}) \\\n",
    "                    .groupby('FIO_MD') \\\n",
    "                    .agg({'SUM_RUB': 'mean'}) \\\n",
    "                    .round() \\\n",
    "                    .astype(int) \\\n",
    "                    .rename(columns={'SUM_RUB': 'avg_rub'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость ТАП в рублях по месяцам\n",
    "\n",
    "avg_rub_by_doc_month = df_all \\\n",
    "                        .groupby(['FIO_MD', 'NHISTORY', 'OT_PER_U'], as_index=False) \\\n",
    "                        .agg({'SUM_RUB': 'sum'}) \\\n",
    "                        .groupby(['FIO_MD', 'OT_PER_U']) \\\n",
    "                        .agg({'SUM_RUB': 'mean'}) \\\n",
    "                        .round() \\\n",
    "                        .astype(int) \\\n",
    "                        .rename(columns={'SUM_RUB': 'avg_rub'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость УЕТ\n",
    "# RPU - rub per uet - стоимость 1 УЕТы\n",
    "\n",
    "avg_uet_rub = df_all \\\n",
    "                    .groupby('FIO_MD', as_index=False) \\\n",
    "                    .agg({'SUM_RUB': 'sum', 'SUM_UET': 'sum'})\n",
    "avg_uet_rub['RPU'] = round(avg_uet_rub['SUM_RUB'] / avg_uet_rub['SUM_UET'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость УЕТ по месяцам\n",
    "# RPU - rub per uet - стоимость 1 УЕТы\n",
    "\n",
    "avg_uet_rub_month = df_all \\\n",
    "                        .groupby(['FIO_MD', 'OT_PER_U'], as_index=False) \\\n",
    "                        .agg({'SUM_RUB': 'sum', 'SUM_UET': 'sum'})\n",
    "avg_uet_rub_month['RPU'] = round(avg_uet_rub_month['SUM_RUB'] / avg_uet_rub_month['SUM_UET'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# По-хорошему написать функцию получения рабочего/нерабочего дня и часла рабочих дней в году\n",
    "# Пока такой бэйзлайн\n",
    "\n",
    "# Создадим список нерабочих дней и рабочих суббот\n",
    "\n",
    "holidays = ['2022-01-03', '2022-01-04', '2022-01-05', '2022-01-06', '2022-01-07',\n",
    "            '2022-01-07', '2022-02-23', '2022-03-07', '2022-03-08', '2022-05-02',\n",
    "            '2022-05-03', '2022-05-09', '2022-05-10', '2022-06-13', '2022-11-04']\n",
    "working_saturday = ['2022-03-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рабочие дни по месяцам в 2022 году\n",
    "\n",
    "working_days_by_month = {1: 16, 2: 19, 3: 22, 4: 21, 5: 18, 6: 21,\n",
    "                         7: 21, 8: 23, 9: 22, 10: 21, 11: 21, 12: 22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь будет максимальная дата, загруженная из dbf\n",
    "\n",
    "with open('last_date.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "last_dbf_date = config['last_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Зашифруем IDCASE, выгрузим csv для даша\n",
    "\n",
    "df_to_dash = df_all[['OT_PER', 'CODE_USL', 'DATE_IN', 'KOL_USL', 'TARIF_B', 'SUM_RUB', 'MSK_OT',\n",
    "                     'CODE_OTD', 'KOL_UET', 'FIO_MD', 'fio_short', 'SUM_UET', 'spec', 'IDCASE']]\n",
    "df_to_dash['TEETH_CODE'] = np.nan\n",
    "df_to_dash['id'] = df_to_dash['IDCASE'].apply(lambda x: hashlib.sha1(str(x).encode()).hexdigest())\n",
    "\n",
    "# В текущем месяце мы не грузим последний незавершенный день\n",
    "# Если вдруг у нас максимальная дата в данных больше, чем сегодня, то мы это увидим в заголовке дашборда\n",
    "# А потеря ошибочно отсеченного день будет практически незаметна\n",
    "\n",
    "# Когда автоматизируем загрузку данных до начала рабочего дня, то эту проверку надо будет убрать\n",
    "# Если загружаем текущий месяц, то последний день надо удрать, так как данные за последний день не полные\n",
    "if df_to_dash['DATE_IN'].max().month == pd.Timestamp.today().month:\n",
    "    df_to_dash = df_to_dash[df_to_dash['DATE_IN'] < df_to_dash['DATE_IN'].max()]\n",
    "\n",
    "# Отметим рабочий или нерабочий день\n",
    "df_to_dash['is_business_day'] = df_to_dash['DATE_IN'].isin(working_saturday) | \\\n",
    "                                        (~(df_to_dash['DATE_IN'].isin(holidays)) & \n",
    "                                         ~(df_to_dash['DATE_IN'].dt.dayofweek >= 5))\n",
    "\n",
    "# Отметим дежурные субботы\n",
    "df_to_dash['is_saturday'] = ((df_to_dash['DATE_IN'].dt.dayofweek == 5) & ~df_to_dash['DATE_IN'].isin(working_saturday))\n",
    "    \n",
    "df_to_dash \\\n",
    "    .drop(columns=['FIO_MD', 'IDCASE']) \\\n",
    "    .to_csv('dash_data.csv', sep=';', index=False)    \n",
    "\n",
    "df_to_dash \\\n",
    "    .query('DATE_IN <= @last_dbf_date') \\\n",
    "    .drop(columns=['fio_short', 'id']) \\\n",
    "    .to_csv('dash_data_superset.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_to_dash.groupby('DATE_IN').agg({'SUM_UET': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим какое предсказание выполнения плана лучше\n",
    "# monthly - относительно среднего выполнения в день за текущий месяц\n",
    "# totally - относительно среднего выполнения в день за весь период\n",
    "\n",
    "df_check_prediction = df_to_dash.query('MSK_OT != \"50\"')\n",
    "df_check_prediction['month'] = df_check_prediction['DATE_IN'].dt.month\n",
    "df_check_prediction['plan_bdays'] = df_check_prediction \\\n",
    "                                        .OT_PER.str[0:2] \\\n",
    "                                        .apply(int) \\\n",
    "                                        .map(working_days_by_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df_check_prediction.groupby('DATE_IN').agg({'SUM_UET': 'sum',\n",
    "                                                       'is_business_day': 'min',\n",
    "                                                       'plan_bdays': 'min'})\n",
    "df_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поэтому пробежим по датафрейму и в словари будем записывать накопительные суммы по месяцу\n",
    "# Переписать df.groupby(df.index.month)['n'].cumsum()\n",
    "\n",
    "month = df_check.index[0].month\n",
    "s = 0\n",
    "d = 0\n",
    "max_uet = 0\n",
    "rolling_sum = {}\n",
    "rolling_days = {}\n",
    "uet_fact = {}\n",
    "uet_monthly_fact = {}\n",
    "\n",
    "for index, row in df_check.iterrows():\n",
    "    if month == index.month:\n",
    "        s += row['SUM_UET']\n",
    "        rolling_sum[index] = s\n",
    "        \n",
    "        d += row['is_business_day']\n",
    "        rolling_days[index] = d\n",
    "        \n",
    "        if s > max_uet:\n",
    "            max_uet = s\n",
    "        uet_fact[month] = s\n",
    "        \n",
    "    else:\n",
    "        s = 0\n",
    "        s += row['SUM_UET']\n",
    "        rolling_sum[index] = s\n",
    "        \n",
    "        d = 0\n",
    "        d += row['is_business_day']\n",
    "        rolling_days[index] = d\n",
    "        \n",
    "        month = index.month\n",
    "        max_uet = s\n",
    "        uet_fact[month] = s\n",
    "        \n",
    "for index, row in df_check.iterrows():\n",
    "    uet_monthly_fact[index] = uet_fact[index.month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rol_sum = pd.Series(data=rolling_sum, name='rol_sum_monthly')\n",
    "rol_days = pd.Series(data=rolling_days, name='rol_days_monthly')\n",
    "monthly_fact_uet = pd.Series(data=uet_monthly_fact, name='monthly_fact_uet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check['cum_sum_uet'] = df_check.SUM_UET.cumsum()\n",
    "df_check['cum_sum_days'] = df_check.is_business_day.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df_check \\\n",
    "            .merge(rol_sum, left_index=True, right_index=True) \\\n",
    "            .merge(rol_days, left_index=True, right_index=True) \\\n",
    "            .merge(monthly_fact_uet, left_index=True, right_index=True) \\\n",
    "            .query('is_business_day > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check['avg_monthly'] = df_check['rol_sum_monthly'] / df_check['rol_days_monthly']\n",
    "df_check['avg_total'] = df_check['cum_sum_uet'] / df_check['cum_sum_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check['plan_uet'] = 34546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check['predict_monthly'] = df_check['rol_sum_monthly'] + \\\n",
    "                                (df_check['plan_bdays'] - df_check['rol_days_monthly']) * df_check['avg_monthly']\n",
    "df_check['predict_totally'] = df_check['rol_sum_monthly'] + \\\n",
    "                                (df_check['plan_bdays'] - df_check['rol_days_monthly']) * df_check['avg_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прогноз на основании среднедневного выполнения за текущий месяц более точное для конкретного набора данных\n",
    "\n",
    "px.line(data_frame=df_check[['predict_monthly', 'predict_totally', 'monthly_fact_uet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df_check[['plan_uet', 'predict_monthly', 'predict_totally', 'rol_sum_monthly']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check_prediction.set_index('DATE_IN', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_dash.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_dash \\\n",
    "    .query('DATE_IN >= \"2022-06-01\"') \\\n",
    "    .groupby('DATE_IN') \\\n",
    "    .agg({'SUM_UET': 'sum'}).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_all.groupby(['FIO_MD', 'NHISTORY']).agg({'SUM_UET': 'sum'}), kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(df_all.groupby(['FIO_MD', 'NHISTORY']).agg({'SUM_UET': 'sum'})), kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединим все в итоговую таблицу, в качестве базы возьмем уникальных врачей из исходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_all.groupby('FIO_MD').agg({'NHISTORY': 'nunique'}).rename(columns={'NHISTORY': 'tap_count'})\n",
    "df_result = df_result \\\n",
    "                .merge(priem_by_doc, how='left', left_index=True, right_index=True) \\\n",
    "                .merge(filling_by_doc, how='left', left_index=True, right_index=True) \\\n",
    "                .merge(devit_by_doc, how='left', left_index=True, right_index=True) \\\n",
    "                .merge(top_diag_by_doc, how='left', left_index=True, right_index=True) \\\n",
    "                .merge(avg_rub_by_doc, how='left', left_index=True, right_index=True) \\\n",
    "                .fillna(0) \\\n",
    "                .astype(int) \\\n",
    "                .merge(avg_uet_by_doc, how='left', left_index=True, right_index=True) \\\n",
    "                .drop(columns='tap_count') \\\n",
    "                .reset_index() \\\n",
    "                .merge(avg_uet_rub[['FIO_MD', 'RPU']], on='FIO_MD') \\\n",
    "                .rename(columns={'FIO_MD': 'Врач', 'preim': 'Приемов', 'filling': 'Пломб', 'devit': 'Мышьяков'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_by_month = df_all \\\n",
    "                        .groupby(['FIO_MD', 'OT_PER_U']) \\\n",
    "                        .agg({'NHISTORY': 'nunique'}) \\\n",
    "                        .rename(columns={'NHISTORY': 'tap_count'}) \\\n",
    "                        .merge(priem_by_doc_month, how='left', left_index=True, right_index=True) \\\n",
    "                        .merge(filling_by_doc_month, how='left', left_index=True, right_index=True) \\\n",
    "                        .merge(devit_by_doc_month, how='left', left_index=True, right_index=True) \\\n",
    "                        .merge(top_diag_by_doc_month, how='left', left_index=True, right_index=True) \\\n",
    "                        .merge(avg_rub_by_doc_month, how='left', left_index=True, right_index=True) \\\n",
    "                        .fillna(0) \\\n",
    "                        .astype(int) \\\n",
    "                        .merge(avg_uet_by_doc_month, how='left', left_index=True, right_index=True) \\\n",
    "                        .drop(columns='tap_count') \\\n",
    "                        .reset_index() \\\n",
    "                        .merge(avg_uet_rub_month[['FIO_MD', 'OT_PER_U', 'RPU']], on=['FIO_MD', 'OT_PER_U']) \\\n",
    "                        .rename(columns={'FIO_MD': 'Врач', 'preim': 'Приемов', 'filling': 'Пломб', \n",
    "                                         'devit': 'Мышьяков', 'OT_PER_U': 'Месяц'})                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPV - filling per visit - отношение числа пломб к числу приемов\n",
    "# DPV - devitalization per vizit - отношение числа мышьяков к числу приемов\n",
    "\n",
    "df_result['FPV'] = df_result['Пломб'] / df_result['Приемов']\n",
    "df_result['DPV'] = df_result['Мышьяков'] / df_result['Приемов']\n",
    "df_result['DPV %'] = df_result['DPV'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики мо месяцам\n",
    "# FPV - filling per visit - отношение числа пломб к числу приемов\n",
    "# DPV - devitalization per vizit - отношение числа мышьяков к числу приемов\n",
    "\n",
    "df_result_by_month['FPV'] = df_result_by_month['Пломб'] / df_result_by_month['Приемов']\n",
    "df_result_by_month['DPV'] = df_result_by_month['Мышьяков'] / df_result_by_month['Приемов']\n",
    "df_result_by_month['DPV %'] = df_result_by_month['DPV'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AD_HOC запрос\n",
    "\n",
    "df_all \\\n",
    "    .query('spec == \"тер\" & OT_PER != \"0622\" & MSK_OT != \"50\" & MSK_OT != \"99\"') \\\n",
    "    .groupby(['FIO_MD', 'OT_PER'], as_index=False) \\\n",
    "    .agg({'SUM_UET': 'sum'}) \\\n",
    "    .groupby('FIO_MD') \\\n",
    "    .describe() \\\n",
    "    .round(1) \\\n",
    "    .to_excel('doc_stat.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all \\\n",
    "    .query('OT_PER != \"0622\" & MSK_OT != \"50\" & MSK_OT != \"99\"') \\\n",
    "    .groupby(['spec', 'OT_PER']) \\\n",
    "    .agg({'NHISTORY': 'nunique'}) \\\n",
    "    .sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all \\\n",
    "    .query('OT_PER != \"0622\" & MSK_OT != \"50\" & MSK_OT != \"99\"') \\\n",
    "    .groupby(['spec', 'OT_PER'], as_index=False) \\\n",
    "    .agg({'NHISTORY': 'nunique'}) \\\n",
    "    .groupby('spec') \\\n",
    "    .describe() \\\n",
    "    .round(1) \\\n",
    "    .to_excel('visit_stat.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_excel(f'Лечение_{year}.xlsx', index=False)\n",
    "df_result_by_month.to_excel(f'Лечение_по_месяцам_{year}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_by_doc.groupby('MKB1', as_index=False) \\\n",
    "    .agg({'diag_count': 'sum'}) \\\n",
    "    .sort_values('diag_count', ascending=False) \\\n",
    "    .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Число пломб на приеме по врачу (средний FPV за год)\n",
    "\n",
    "px.bar(df_result.query('(FPV > 0) & (Врач != \"Коваленко Ольга Эдуардовна физио\")').sort_values('FPV', ascending=False), \n",
    "       x='Врач',\n",
    "       y='FPV',\n",
    "       title=f\"Число пломб на приеме в {year} году\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделать grayscale\n",
    "\n",
    "greys = n_colors('rgb(100, 100, 100)', 'rgb(255, 255, 255)', len(df_result_by_month['Месяц'].unique())+1, colortype='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Средний FPV по месяцам и врачу (ч/б)\n",
    "\n",
    "px.bar(df_result_by_month.query('(FPV > 0) & (Врач != \"Коваленко Ольга Эдуардовна физио\")'), \n",
    "       x='Врач',\n",
    "       y='FPV',\n",
    "       color='Месяц',\n",
    "       barmode='group',\n",
    "       color_discrete_sequence=greys,\n",
    "       title=f\"Число пломб на приеме в {year} году\").update_xaxes(categoryorder='total descending') \\\n",
    "    .update_layout(plot_bgcolor='rgb(255,255,255)') \\\n",
    "    .update_yaxes(gridcolor='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средний FPV по месяцам и врачу (цвет)\n",
    "\n",
    "px.bar(df_result_by_month.query('(FPV > 0) & (Врач != \"Коваленко Ольга Эдуардовна физио\")'), \n",
    "       x='Врач',\n",
    "       y='FPV',\n",
    "       color='Месяц',\n",
    "       barmode='group',\n",
    "       title=f\"Число пломб на приеме в {year} году\").update_xaxes(categoryorder='total descending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средний DPV за год по врачу\n",
    "\n",
    "px.bar(df_result.query('DPV > 0').sort_values('DPV', ascending=False), \n",
    "       x='Врач',\n",
    "       y='DPV %',\n",
    "       title=f\"Процент приемов с мышьяком в {year} году\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPV по месяцу и врачу (ч/б)\n",
    "\n",
    "px.bar(df_result_by_month.query('DPV > 0'), \n",
    "       x='Врач',\n",
    "       y='DPV %',\n",
    "       color='Месяц',\n",
    "       barmode='group',\n",
    "       color_discrete_sequence=greys,\n",
    "       title=f\"Процент приемов с мышьяком в {year} году\").update_xaxes(categoryorder='total descending') \\\n",
    "    .update_layout(plot_bgcolor='rgb(255,255,255)') \\\n",
    "    .update_yaxes(gridcolor='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPV по месяцу и врачу (цвет)\n",
    "\n",
    "px.bar(df_result_by_month.query('DPV > 0'), \n",
    "       x='Врач',\n",
    "       y='DPV %',\n",
    "       color='Месяц',\n",
    "       barmode='group',\n",
    "       title=f\"Процент приемов с мышьяком в {year} году\").update_xaxes(categoryorder='total descending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость ТАП в руб по врачу\n",
    "\n",
    "px.bar(df_result.sort_values('avg_rub', ascending=False), \n",
    "       x='Врач',\n",
    "       y='avg_rub',\n",
    "       title=f'Средняя стоимость ТАП в руб. за {year} году') \\\n",
    "    .update_yaxes(title_text = 'Руб')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость ТАП в руб по врачу и месяцу (ч/б), вертикальные бары\n",
    "\n",
    "px.bar(df_result_by_month, \n",
    "       x='Врач',\n",
    "       y='avg_rub',\n",
    "       color='Месяц',\n",
    "       barmode='group',\n",
    "       width=1060,\n",
    "       color_discrete_sequence=greys,\n",
    "       title=f'Средняя стоимость ТАП в руб. за {year} году') \\\n",
    "    .update_layout(plot_bgcolor='rgb(255,255,255)') \\\n",
    "    .update_yaxes(title_text = 'Руб', gridcolor='grey') \\\n",
    "    .update_xaxes(categoryorder='total descending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Средняя стоимость ТАП в руб по врачу и месяцу (цв), горизонтальные бары\n",
    "\n",
    "px.bar(df_result_by_month, \n",
    "       y='Врач',\n",
    "       x='avg_rub',\n",
    "       color='Месяц',\n",
    "       barmode='group',\n",
    "#        width=1060,\n",
    "       height = 2000,\n",
    "       orientation = 'h',\n",
    "       title=f'Средняя стоимость ТАП в руб. за {year} году') \\\n",
    "    .update_yaxes(title_text = 'Руб', categoryorder='total ascending') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость ТАП в УЕТ по врачу\n",
    "\n",
    "px.bar(df_result.sort_values('avg_uet', ascending=False), \n",
    "       x='Врач',\n",
    "       y='avg_uet',\n",
    "       title=f'Средняя стоимость ТАП в УЕТ за {year} год') \\\n",
    "    .update_yaxes(title_text = 'УЕТ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость ТАП в УЕТ по врачу и месяцу (ч/б)\n",
    "\n",
    "px.bar(df_result_by_month, \n",
    "       x='Врач',\n",
    "       y='avg_uet',\n",
    "       color='Месяц',\n",
    "       barmode='group',\n",
    "       width=1660,\n",
    "       color_discrete_sequence=greys,\n",
    "       title=f'Среднее количество УЕТ в ТАП за {year} год') \\\n",
    "    .update_layout(plot_bgcolor='rgb(255,255,255)') \\\n",
    "    .update_yaxes(title_text = 'УЕТ', gridcolor='grey') \\\n",
    "    .update_xaxes(categoryorder='total descending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость ТАП в УЕТ по врачу и месяцу (цв)\n",
    "\n",
    "px.bar(df_result_by_month, \n",
    "       x='Врач',\n",
    "       y='avg_uet',\n",
    "       color='Месяц',\n",
    "       barmode='group',\n",
    "       width=1660,\n",
    "       title=f'Среднее количество УЕТ в ТАП за {year} год') \\\n",
    "    .update_yaxes(title_text = 'УЕТ') \\\n",
    "    .update_xaxes(categoryorder='total descending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость 1 УЕТ в руб по врачу\n",
    "\n",
    "px.bar(df_result.query('Врач != \"Коваленко Ольга Эдуардовна физио\"').sort_values('RPU', ascending=False), \n",
    "                x='Врач',\n",
    "                y='RPU',\n",
    "                title=f'Средняя стоимость 1 УЕТ в руб за {year} год (план: {mean_uet})',\n",
    "                text='RPU',\n",
    "                width=1360) \\\n",
    "    .update_traces(textfont_size=20, textposition=\"outside\", textangle=-45, cliponaxis=False) \\\n",
    "    .update_layout(plot_bgcolor='rgb(255,255,255)')\n",
    "# fig.show(renderer=\"notebook_connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость 1 УЕТ в руб по врачу и месяцу (ч/б)\n",
    "\n",
    "px.bar(df_result_by_month.query('Врач != \"Коваленко Ольга Эдуардовна физио\"'), \n",
    "                x='Врач',\n",
    "                y='RPU',\n",
    "                title=f'Средняя стоимость 1 УЕТ в руб за {year} год (план: {mean_uet})',\n",
    "                text='RPU',\n",
    "                color='Месяц',\n",
    "                barmode='group',\n",
    "                color_discrete_sequence=greys,\n",
    "                width=1360) \\\n",
    "    .update_layout(plot_bgcolor='rgb(255,255,255)') \\\n",
    "    .update_yaxes(gridcolor='grey', dtick = 167.7) \\\n",
    "    .update_xaxes(categoryorder='total descending') \\\n",
    "#     .update_traces(textfont_size=20, textposition=\"outside\", textangle=-45, cliponaxis=False) \\\n",
    "# fig.show(renderer=\"notebook_connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя стоимость 1 УЕТ в руб по врачу и месяцу (цв)\n",
    "\n",
    "px.bar(df_result_by_month.query('Врач != \"Коваленко Ольга Эдуардовна физио\"'), \n",
    "                x='Врач',\n",
    "                y='RPU',\n",
    "                title=f'Средняя стоимость 1 УЕТ в руб за {year} год (план: {mean_uet})',\n",
    "                text='RPU',\n",
    "                color='Месяц',\n",
    "                barmode='group',\n",
    "                width=1360) \\\n",
    "    .update_yaxes(gridcolor='black', dtick = 167.7) \\\n",
    "    .update_xaxes(categoryorder='total descending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ниже work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рабочих дней в текущем месяце\n",
    "\n",
    "wdays_passed = df_to_dash[(df_to_dash['DATE_IN'].dt.month == df_to_dash['DATE_IN'].max().month) &\n",
    "                          (df_to_dash['DATE_IN'].dt.dayofweek < 5)] \\\n",
    "                    .query('DATE_IN not in @holidays') \\\n",
    "                    .DATE_IN.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Суббот (в данных) в текущем месяце\n",
    "\n",
    "saturday_passed = df_to_dash[(df_to_dash['DATE_IN'].dt.month == df_to_dash['DATE_IN'].max().month) &\n",
    "                             (df_to_dash['DATE_IN'].dt.dayofweek == 5)] \\\n",
    "                        .query('DATE_IN not in @working_saturday') \\\n",
    "                        .DATE_IN.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Число рабочих дней в текущем месяце\n",
    "\n",
    "wdyas_month = working_days_by_month[df_to_dash['DATE_IN'].max().month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Осталось рабочих дней\n",
    "\n",
    "wdays_remain = wdyas_month - wdays_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Всего число суббот в текущем месяце\n",
    "\n",
    "month_end = df_to_dash['DATE_IN'].max() + MonthEnd(1)\n",
    "month_begin = df_to_dash['DATE_IN'].max() - MonthBegin(1)\n",
    "\n",
    "# Делаем + 1, т.к. разница month_end - month_begin теряет 1 день\n",
    "num_weeks, remainder = divmod((month_end - month_begin).days + 1, 7)  \n",
    "if (5 - month_begin.weekday()) % 7 < remainder:\n",
    "    saturdays_month = num_weeks + 1\n",
    "else:\n",
    "    saturdays_month = num_weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturdays_remain = saturdays_month - saturday_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Среднее число и стоимость ТАП с начала года по будням по специальности\n",
    "# Так как считаем план, то берем без МТР\n",
    "\n",
    "df_to_dash[(df_to_dash['DATE_IN'].dt.dayofweek < 5) & \n",
    "           (df_to_dash['DATE_IN'] > '2022-01-09')] \\\n",
    "    .query('(DATE_IN not in @holidays) & (MSK_OT !=\"50\")') \\\n",
    "    .groupby('spec') \\\n",
    "    .agg({'IDCASE': 'nunique', 'DATE_IN': 'nunique', 'SUM_UET': 'sum'}) \\\n",
    "    .assign(avg_tap        = lambda x: x['IDCASE'] / x['DATE_IN'],\n",
    "            avg_uet_tap    = lambda x: x['SUM_UET'] / x['IDCASE'],\n",
    "            uet_per_day    = lambda x: x['avg_tap'] * x['avg_uet_tap'],\n",
    "            uet_this_month = lambda x: x['uet_per_day'] * wdays_remain).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Среднее число и стоимость ТАП с начала года по субботам по специальности (2022-03-05 - рабочая суббота)\n",
    "\n",
    "df_to_dash[(df_to_dash['DATE_IN'].dt.dayofweek == 5) & \n",
    "           (df_to_dash['DATE_IN'] > '2022-01-09')] \\\n",
    "    .query('(DATE_IN not in @working_saturday) & (MSK_OT !=\"50\")') \\\n",
    "    .groupby('spec') \\\n",
    "    .agg({'IDCASE': 'nunique', 'DATE_IN': 'nunique', 'SUM_UET': 'sum'}) \\\n",
    "    .assign(avg_tap        = lambda x: x['IDCASE'] / x['DATE_IN'],\n",
    "            avg_uet_tap    = lambda x: x['SUM_UET'] / x['IDCASE'],\n",
    "            uet_per_day    = lambda x: x['avg_tap'] * x['avg_uet_tap'],\n",
    "            uet_this_month = lambda x: x['uet_per_day'] * saturdays_remain).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_dash[(df_to_dash['DATE_IN'] >= '2022-05-01')] \\\n",
    "    .query('MSK_OT !=\"50\"') \\\n",
    "    .groupby('spec') \\\n",
    "    .agg({'SUM_UET': 'sum'}).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Число рабочих дней по врачам с указанием специальности\n",
    "\n",
    "working_days = df_all.groupby(['FIO_MD', 'PRVS', 'DATE_IN'], as_index=False) \\\n",
    "                        .agg({'NHISTORY': 'nunique', 'SUM_UET': 'sum', 'SUM_RUB': 'sum'}) \\\n",
    "                        .groupby('FIO_MD') \\\n",
    "                        .agg({'PRVS': 'min', 'DATE_IN': 'count', 'SUM_UET': 'sum', 'SUM_RUB': 'sum', 'NHISTORY': 'mean'})\n",
    "working_days['spec'] = working_days \\\n",
    "                            .PRVS \\\n",
    "                            .map({208: 'тер', 72: 'хир', 69: 'тер', 71: 'тер', 87: 'физио'})\n",
    "working_days.drop(columns='PRVS', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_days.SUM_RUB.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_days.SUM_UET.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Среднедневная выработка УЕТ по специальностям\n",
    "\n",
    "working_days.groupby('spec').agg({'SUM_UET': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Статистика по талонам в день\n",
    "\n",
    "working_days.query('spec == \"тер\"').NHISTORY.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Число рабочих дней в год по специальности (факт)\n",
    "# План по терапевтам 4047 (19 врачей Скалкович+Кукушкина пока принимают условно по 0.5 приема) по средней в 213 дней)\n",
    "# План по терапевтам 3990 (19 врачей Скалкович+Кукушкина пока принимают условно по 0.5 приема) по медиане 210 дней)\n",
    "# План по хирургам 1314 (6 врачей по 219 дней - среднее по факту 2021 года при медиане 223)\n",
    "\n",
    "working_days.groupby('spec').agg({'DATE_IN': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Статистика по числу рабочих дней\n",
    "\n",
    "working_days.query('spec == \"тер\"').DATE_IN.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Медианное число рабочих дней терапевтов в 2021 (факт) - Медианное число рабочих дней терапевтов в 2022\n",
    "\n",
    "ter_days = 210 - working_days.query('spec == \"тер\"').DATE_IN.median()\n",
    "ter_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Медианное число рабочих дней хирургов в 2021 (факт) - Медианное число рабочих дней хирургов в 2022\n",
    "# Чистая медиана 223\n",
    "# Среднее без Саркисова 219\n",
    "\n",
    "hir_days = 219 - working_days.query('spec == \"хир\"').DATE_IN.median()\n",
    "hir_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Плановые расчеты ниже возможно не завершены (основной расчет был в ноутбуке за 2021 год)\n",
    "\n",
    "# План на 2022 год\n",
    "\n",
    "plan2022_oms = 414548\n",
    "plan2022_total = 414548*100/88\n",
    "plan2022_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# План по специальностям на 2022 год\n",
    "\n",
    "ter_plan = plan2022_total*78.8/100\n",
    "hir_plan = plan2022_total*17.9/100\n",
    "fizio_plan = plan2022_total*3.3/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Число врачей по специальностям\n",
    "ter_count = 19\n",
    "hir_count = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# План на 2022 год без января\n",
    "\n",
    "plan2022_corr = plan2022_total - working_days.SUM_UET.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# План по специальностям на 2022 год без января\n",
    "\n",
    "ter_plan_corr = plan2022_corr*78.8/100\n",
    "hir_plan_corr = plan2022_corr*17.9/100\n",
    "fizio_plan_corr = plan2022_corr*3.3/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ter_plan_corr/ter_count/ter_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hir_plan_corr/hir_count/hir_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fizio_plan_corr/1/253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "plan2022_total/12 - working_days.SUM_UET.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Число рабочих дней по врачам с указанием специальности\n",
    "\n",
    "working_days = df_all.groupby(['FIO_MD', 'PRVS', 'DATE_IN'], as_index=False) \\\n",
    "                        .agg({'NHISTORY': 'nunique', 'SUM_UET': 'sum'}) \\\n",
    "                        .groupby('FIO_MD') \\\n",
    "                        .agg({'PRVS': 'min', 'DATE_IN': 'count', 'SUM_UET': 'mean', 'NHISTORY': 'mean'})\n",
    "working_days['spec'] = working_days \\\n",
    "                            .PRVS \\\n",
    "                            .map({208: 'тер', 72: 'хир', 69: 'тер', 71: 'тер', 87: 'физио'})\n",
    "working_days.drop(columns='PRVS', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполнение УЕТ по дням и количество врачей по специальностям в этот день\n",
    "\n",
    "uet_by_day = df_all \\\n",
    "                .groupby(['DATE_IN', 'spec'], as_index=False) \\\n",
    "                .agg({'FIO_MD': 'nunique'}) \\\n",
    "                .pivot(index='DATE_IN', columns='spec', values='FIO_MD') \\\n",
    "                .fillna(0) \\\n",
    "                .astype('int32') \\\n",
    "                .merge(df_all \\\n",
    "                        .groupby('DATE_IN') \\\n",
    "                        .agg({'SUM_UET': 'sum'}),\n",
    "                       on='DATE_IN',\n",
    "                       how='left'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uet_by_day[uet_by_day.index.dayofweek < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Среднее УЕТ в день\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.lineplot(data=uet_by_day[uet_by_day.index.dayofweek < 5], \n",
    "             x='DATE_IN', \n",
    "             y=uet_by_day[uet_by_day.index.dayofweek < 5].SUM_UET,\n",
    "             label='УЕТ')\n",
    "sns.lineplot(data=uet_by_day[uet_by_day.index.dayofweek < 5], \n",
    "             x='DATE_IN', \n",
    "             y=(uet_by_day[uet_by_day.index.dayofweek < 5].тер)*100,\n",
    "             label='Число терапевтов')\n",
    "sns.lineplot(data=uet_by_day[uet_by_day.index.dayofweek < 5], \n",
    "             x='DATE_IN', \n",
    "             y=(uet_by_day[uet_by_day.index.dayofweek < 5].хир)*100,\n",
    "             label='Число хирургов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uet_by_day[uet_by_day.index.dayofweek < 5].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uet_by_day[uet_by_day.index.dayofweek < 5].corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uet_by_day[uet_by_day.index.dayofweek < 5].corr(method='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
